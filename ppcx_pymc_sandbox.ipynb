{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e564560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from src.clustering import preproc_features\n",
    "from src.config import ConfigManager\n",
    "from src.database import (\n",
    "    get_dic_analysis_by_ids,\n",
    "    get_dic_analysis_ids,\n",
    "    get_dic_data,\n",
    "    get_image,\n",
    "    get_multi_dic_data,\n",
    ")\n",
    "from src.preprocessing import apply_dic_filters, spatial_subsample\n",
    "from src.roi import PolygonROISelector, filter_dataframe\n",
    "\n",
    "%matplotlib widget\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Load configuration\n",
    "config = ConfigManager()\n",
    "db_engine = create_engine(config.db_url)\n",
    "\n",
    "# Parameters\n",
    "target_date = \"2024-08-23\"\n",
    "camera_name = \"PPCX_Tele\"\n",
    "\n",
    "dic_id = 629\n",
    "\n",
    "base_output_dir = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2bde16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 DIC analyses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:37:03,238 - INFO - Starting DIC filtering pipeline with 5251 points\n",
      "2025-08-28 11:37:03,243 - INFO - Percentile filtering: 5251 -> 5147 points (removed 104 outliers)\n",
      "2025-08-28 11:37:03,244 - INFO - Min velocity filtering: 5147 -> 3835 points (removed 1312 points below 1)\n",
      "2025-08-28 11:37:03,245 - INFO - Applying 2D median filter: window_size=5, threshold_factor=3.0\n",
      "2025-08-28 11:37:03,253 - INFO - Estimated grid spacing: 64.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DIC ID: 629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:37:03,430 - INFO - Created 2D grid: (89, 59), 3835 valid points\n",
      "2025-08-28 11:37:03,434 - INFO - Detected 362 outliers in 2D median filter\n",
      "2025-08-28 11:37:03,598 - INFO - 2D median filtering: 3835 -> 3473 points (removed 362 outliers)\n",
      "2025-08-28 11:37:03,599 - INFO - DIC filtering pipeline completed: 5251 -> 3473 points (removed 1778 total)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 3473 points to 2138 points inside polygon\n",
      "Data shape after filtering: (2138, 5)\n",
      "Data shape before subsampling: (2138, 5)\n",
      "Subsampled from 2138 to 1069 points (50.0%)\n",
      "Data shape after subsampling: (1069, 5)\n",
      "Using features: ['V']\n",
      "Feature matrix shape: (1069, 1)\n"
     ]
    }
   ],
   "source": [
    "# === DATA EXTRACTION ===\n",
    "\n",
    "# Get DIC analysis metadata\n",
    "dic_ids = get_dic_analysis_ids(\n",
    "    db_engine, reference_date=target_date, camera_name=camera_name\n",
    ")\n",
    "print(f\"Found {len(dic_ids)} DIC analyses\")\n",
    "dic_analyses = get_dic_analysis_by_ids(db_engine=db_engine, dic_ids=dic_ids)\n",
    "\n",
    "# Get master image\n",
    "master_image_id = dic_analyses[\"master_image_id\"].iloc[0]\n",
    "img = get_image(master_image_id, camera_name=camera_name)\n",
    "\n",
    "# Fetch DIC data\n",
    "if len(dic_ids) == 0:\n",
    "    raise ValueError(\"No DIC analyses found for the given criteria\")\n",
    "elif len(dic_ids) == 1:\n",
    "    print(f\"Using DIC ID: {dic_ids[0]}\")\n",
    "    df = get_dic_data(dic_ids[0])\n",
    "else:\n",
    "    df = get_multi_dic_data(dic_ids)\n",
    "\n",
    "# Apply filters\n",
    "df = apply_dic_filters(\n",
    "    df,\n",
    "    filter_outliers=config.get(\"dic.filter_outliers\"),\n",
    "    tails_percentile=config.get(\"dic.tails_percentile\"),\n",
    "    min_velocity=config.get(\"dic.min_velocity\"),\n",
    "    apply_2d_median=config.get(\"dic.apply_2d_median\"),\n",
    "    median_window_size=config.get(\"dic.median_window_size\"),\n",
    "    median_threshold_factor=config.get(\"dic.median_threshold_factor\"),\n",
    ")\n",
    "\n",
    "# Apply ROI filter\n",
    "selector = PolygonROISelector.from_file(config.get(\"data.roi_path\"))\n",
    "df = filter_dataframe(df, selector.polygon_path, x_col=\"x\", y_col=\"y\")\n",
    "print(f\"Data shape after filtering: {df.shape}\")\n",
    "\n",
    "\n",
    "# Apply subsampling AFTER ROI filtering\n",
    "SUBSAMPLE_FACTOR = 2  # Take every n point\n",
    "SUBSAMPLE_METHOD = \"regular\"  # or 'random', 'stratified'\n",
    "if SUBSAMPLE_FACTOR > 0:\n",
    "    print(f\"Data shape before subsampling: {df.shape}\")\n",
    "    df_subsampled = spatial_subsample(\n",
    "        df, n_subsample=SUBSAMPLE_FACTOR, method=SUBSAMPLE_METHOD\n",
    "    )\n",
    "    df = df_subsampled\n",
    "    print(f\"Data shape after subsampling: {df.shape}\")\n",
    "\n",
    "# === FEATURE PREPARATION ===\n",
    "\n",
    "# Get clustering parameters from config\n",
    "variables_names = config.get(\"clustering.variables_names\")\n",
    "print(f\"Using features: {variables_names}\")\n",
    "\n",
    "# Preprocess features\n",
    "df_features = preproc_features(df)\n",
    "X = df_features[variables_names].values\n",
    "n_features = X.shape[1]\n",
    "ndata = X.shape[0]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
    "\n",
    "# Build output directory\n",
    "output_dir = Path(base_output_dir) / camera_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "base_name = f\"{camera_name}_{target_date}_PyMC_GMM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SPATIAL PRIOR SETUP ===\n",
    "def assign_spatial_priors_dic(df, selectors, prior_strength=0.8):\n",
    "    \"\"\"Assign spatial prior probabilities based on polygon sectors.\"\"\"\n",
    "    ndata = len(df)\n",
    "    k = len(selectors)\n",
    "    prior_probs = np.ones((ndata, k)) / k  # default uniform\n",
    "\n",
    "    for idx, selector in enumerate(selectors):\n",
    "        mask = selector.contains_points(df[\"x\"].values, df[\"y\"].values)\n",
    "        # Strong prior for points inside polygon\n",
    "        prior_probs[mask] = (1 - prior_strength) / (\n",
    "            k - 1\n",
    "        )  # small prob for other clusters\n",
    "        prior_probs[mask, idx] = prior_strength  # high prob for this cluster\n",
    "        print(f\"Sector {idx}: {mask.sum()} points with strong prior\")\n",
    "\n",
    "    return prior_probs\n",
    "\n",
    "\n",
    "# Load sector polygons for priors\n",
    "sector_files = sorted(glob.glob(\"data/sectors_prior/*.json\"))\n",
    "sector_selectors = [PolygonROISelector.from_file(f) for f in sector_files]\n",
    "k = len(sector_selectors)  # number of clusters = number of sectors\n",
    "print(f\"Found {k} sector polygons for priors\")\n",
    "\n",
    "# Assign priors\n",
    "PRIOR_STRENGTH = 0.5\n",
    "prior_probs = assign_spatial_priors_dic(\n",
    "    df, sector_selectors, prior_strength=PRIOR_STRENGTH\n",
    ")\n",
    "\n",
    "# Visualize priors\n",
    "nrows = int(np.ceil(np.sqrt(k)))\n",
    "ncols = int(np.ceil(k / nrows))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n",
    "axes = [axes] if k == 1 else axes.flatten()\n",
    "for cluster in range(k):\n",
    "    axes[cluster].imshow(img, alpha=0.3)\n",
    "    scatter = axes[cluster].scatter(\n",
    "        df[\"x\"],\n",
    "        df[\"y\"],\n",
    "        c=prior_probs[:, cluster],\n",
    "        cmap=\"Reds\",\n",
    "        s=1,\n",
    "        alpha=0.7,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    axes[cluster].set_title(f\"Prior for Cluster {cluster}\")\n",
    "    axes[cluster].xaxis.set_ticks([])\n",
    "    axes[cluster].yaxis.set_ticks([])\n",
    "    plt.colorbar(scatter, ax=axes[cluster])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PYMC MODEL WITH SPATIAL PRIORS ===\n",
    "with pm.Model(\n",
    "    coords={\"cluster\": range(k), \"feature\": range(n_features), \"obs\": range(ndata)}\n",
    ") as model_with_priors:\n",
    "    # Cluster means (multivariate)\n",
    "    μ = pm.Normal(\"μ\", mu=0, sigma=3, dims=(\"cluster\", \"feature\"))\n",
    "\n",
    "    # Cluster standard deviations (diagonal covariance)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=2, dims=(\"cluster\", \"feature\"))\n",
    "\n",
    "    # Cluster assignments with spatial priors\n",
    "    z = pm.Categorical(\"z\", p=prior_probs, dims=\"obs\")\n",
    "\n",
    "    # Likelihood: each point comes from its assigned cluster\n",
    "    pm.Normal(\"x_obs\", mu=μ[z], sigma=σ[z], observed=X_scaled, dims=(\"obs\", \"feature\"))\n",
    "\n",
    "print(\"Model with spatial priors created\")\n",
    "pm.model_to_graphviz(model_with_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAMPLE FROM MODEL ===\n",
    "with model_with_priors:\n",
    "    print(\"Starting MCMC sampling...\")\n",
    "    idata_with_priors = pm.sample(\n",
    "        target_accept=0.9,\n",
    "        draws=1000,\n",
    "        tune=1000,\n",
    "        chains=4,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "print(\"Sampling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d562547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check R-hat (should be < 1.01)\n",
    "print(az.rhat(idata_with_priors))\n",
    "\n",
    "# Check effective sample size (should be > 100)\n",
    "print(az.ess(idata_with_priors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace plots\n",
    "az.plot_trace(idata_with_priors, var_names=[\"μ\", \"σ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = idata_with_priors\n",
    "\n",
    "# Get cluster assignments\n",
    "z_posterior = idata.posterior[\"z\"]\n",
    "z_samples = z_posterior.values.reshape(-1, z_posterior.shape[-1])\n",
    "\n",
    "cluster_pred = np.zeros(z_posterior.shape[-1], dtype=int)\n",
    "for i in range(z_posterior.shape[-1]):\n",
    "    values, counts = np.unique(z_samples[:, i], return_counts=True)\n",
    "    cluster_pred[i] = values[np.argmax(counts)]\n",
    "\n",
    "# Get model parameters\n",
    "mu_posterior = idata.posterior[\"μ\"].mean(dim=[\"chain\", \"draw\"]).values.flatten()\n",
    "sigma_posterior = idata.posterior[\"σ\"].mean(dim=[\"chain\", \"draw\"]).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d66203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1D velocity clustering\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.stats import norm as scipy_norm\n",
    "\n",
    "\n",
    "def plot_1d_velocity_clustering(df_features, idata, img, scaler=None):\n",
    "    \"\"\"Specialized plot for 1D velocity-only clustering.\"\"\"\n",
    "\n",
    "    # Get cluster assignments\n",
    "    z_posterior = idata.posterior[\"z\"]\n",
    "    z_samples = z_posterior.values.reshape(-1, z_posterior.shape[-1])\n",
    "\n",
    "    cluster_pred = np.zeros(z_posterior.shape[-1], dtype=int)\n",
    "    for i in range(z_posterior.shape[-1]):\n",
    "        values, counts = np.unique(z_samples[:, i], return_counts=True)\n",
    "        cluster_pred[i] = values[np.argmax(counts)]\n",
    "\n",
    "    # Get model parameters\n",
    "    mu_posterior = idata.posterior[\"μ\"].mean(dim=[\"chain\", \"draw\"]).values.flatten()\n",
    "    sigma_posterior = idata.posterior[\"σ\"].mean(dim=[\"chain\", \"draw\"]).values.flatten()\n",
    "\n",
    "    # Distinct colors\n",
    "    unique_labels = np.unique(cluster_pred)\n",
    "    colors = [\"#E31A1C\", \"#1F78B4\", \"#33A02C\", \"#FF7F00\", \"#6A3D9A\"][\n",
    "        : len(unique_labels)\n",
    "    ]\n",
    "    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Create figure with custom layout\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 12))\n",
    "\n",
    "    # Plot 1: Spatial clusters\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.set_title(\"Velocity-Based Spatial Clustering\", fontsize=14, pad=10)\n",
    "\n",
    "    if img is not None:\n",
    "        ax1.imshow(img, alpha=0.3, cmap=\"gray\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = cluster_pred == label\n",
    "        if np.any(mask):\n",
    "            ax1.scatter(\n",
    "                df_features.loc[mask, \"x\"],\n",
    "                df_features.loc[mask, \"y\"],\n",
    "                c=color_map[label],\n",
    "                s=8,\n",
    "                alpha=0.8,\n",
    "                label=f\"Velocity Cluster {label}\",\n",
    "                edgecolors=\"none\",\n",
    "            )\n",
    "    ax1.legend(loc=\"upper right\", framealpha=0.9, fontsize=10)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "\n",
    "    # Plot 2: Velocity distribution\n",
    "    ax3 = axes[0, 1]\n",
    "    ax3.set_title(\"Velocity Distribution by Cluster\", fontsize=14, pad=10)\n",
    "\n",
    "    # Plot histograms for each cluster\n",
    "    velocity = df_features[\"V\"].values\n",
    "    for label in unique_labels:\n",
    "        mask = cluster_pred == label\n",
    "        if np.any(mask):\n",
    "            ax3.hist(\n",
    "                velocity[mask],\n",
    "                bins=35,\n",
    "                alpha=0.7,\n",
    "                density=True,\n",
    "                color=color_map[label],\n",
    "                label=f\"Cluster {label}\",\n",
    "                edgecolor=\"white\",\n",
    "                linewidth=0.5,\n",
    "            )\n",
    "\n",
    "    # Overlay model distributions\n",
    "    v_range = np.linspace(velocity.min(), velocity.max(), 200)\n",
    "    for label in unique_labels:\n",
    "        if scaler is not None:\n",
    "            mu_orig = scaler.inverse_transform([[mu_posterior[label]]])[0, 0]\n",
    "            sigma_orig = sigma_posterior[label] * scaler.scale_[0]\n",
    "        else:\n",
    "            mu_orig = mu_posterior[label]\n",
    "            sigma_orig = sigma_posterior[label]\n",
    "\n",
    "        model_dist = scipy_norm.pdf(v_range, mu_orig, sigma_orig)\n",
    "        ax3.plot(\n",
    "            v_range,\n",
    "            model_dist,\n",
    "            \"--\",\n",
    "            color=color_map[label],\n",
    "            linewidth=2.5,\n",
    "            alpha=0.9,\n",
    "            label=f\"Model {label}\",\n",
    "        )\n",
    "    ax3.set_xlabel(\"Velocity Magnitude\", fontsize=12)\n",
    "    ax3.set_ylabel(\"Density\", fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(fontsize=10, framealpha=0.9)\n",
    "\n",
    "    # Plot 3: Velocity field with quiver plot\n",
    "    ax2 = axes[1, 0]\n",
    "    ax2.set_title(\"Velocity Vector Field\", fontsize=14, pad=10)\n",
    "\n",
    "    if img is not None:\n",
    "        ax2.imshow(img, alpha=0.7, cmap=\"gray\")\n",
    "\n",
    "    # Create quiver plot\n",
    "    magnitudes = df_features[\"V\"].to_numpy()\n",
    "    vmin = 0.0\n",
    "    vmax = np.max(magnitudes)\n",
    "    norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    q = ax2.quiver(\n",
    "        df_features[\"x\"].to_numpy(),\n",
    "        df_features[\"y\"].to_numpy(),\n",
    "        df_features[\"u\"].to_numpy(),\n",
    "        df_features[\"v\"].to_numpy(),\n",
    "        magnitudes,\n",
    "        scale=None,\n",
    "        scale_units=\"xy\",\n",
    "        angles=\"xy\",\n",
    "        cmap=\"viridis\",\n",
    "        norm=norm,\n",
    "        width=0.003,\n",
    "        headwidth=2.5,\n",
    "        alpha=1.0,\n",
    "    )\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(q, ax=ax2, shrink=0.8, aspect=20, pad=0.02)\n",
    "    cbar.set_label(\"Velocity Magnitude\", rotation=270, labelpad=15)\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # Plot 4: Statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis(\"off\")\n",
    "    stats_text = \"VELOCITY CLUSTERING STATISTICS\\n\" + \"=\" * 30 + \"\\n\"\n",
    "    for label in unique_labels:\n",
    "        mask = cluster_pred == label\n",
    "        count = mask.sum()\n",
    "\n",
    "        if count == 0:\n",
    "            continue\n",
    "\n",
    "        v_mean = velocity[mask].mean()\n",
    "        v_std = velocity[mask].std()\n",
    "        v_median = np.median(velocity[mask])\n",
    "        nmad = np.median(np.abs(velocity[mask] - v_median)) * 1.4826\n",
    "\n",
    "        # Model parameters (in original scale)\n",
    "        if scaler is not None:\n",
    "            model_mu = scaler.inverse_transform([[mu_posterior[label]]])[0, 0]\n",
    "            model_sigma = sigma_posterior[label] * scaler.scale_[0]\n",
    "        else:\n",
    "            model_mu = mu_posterior[label]\n",
    "            model_sigma = sigma_posterior[label]\n",
    "\n",
    "        stats_text += f\"VELOCITY CLUSTER {label} (pts: {count})\\n\"\n",
    "        stats_text += f\"├─ Velocity: {v_mean:.4f} ± {v_std:.4f}\\n\"\n",
    "        stats_text += f\"├─ Median/NMAD: {v_median:.4f}/{nmad:.4f}\\n\"\n",
    "        stats_text += f\"├─ Model μ/σ: {model_mu:.4f}/{model_sigma:.4f}\\n\\n\"\n",
    "\n",
    "    ax4.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        stats_text,\n",
    "        transform=ax4.transAxes,\n",
    "        fontsize=8,\n",
    "        verticalalignment=\"top\",\n",
    "        fontfamily=\"monospace\",\n",
    "        bbox=dict(\n",
    "            boxstyle=\"round,pad=0.4\", facecolor=\"lightblue\", alpha=0.8, edgecolor=\"navy\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return cluster_pred, fig\n",
    "\n",
    "\n",
    "cluster_pred_1d, fig_1d = plot_1d_velocity_clustering(\n",
    "    df_features, idata_with_priors, img, scaler\n",
    ")\n",
    "fig_1d.savefig(\n",
    "    output_dir / f\"{base_name}_velocity_only_results.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nd_velocity_clustering(\n",
    "    df_features, X_scaled, idata, prior_probs, img, variables_names, scaler=None\n",
    "):\n",
    "    \"\"\"Improved DIC clustering results with comprehensive statistics.\"\"\"\n",
    "\n",
    "    # Get posterior cluster assignments\n",
    "    z_posterior = idata.posterior[\"z\"]\n",
    "    z_samples = z_posterior.values\n",
    "    z_flat = z_samples.reshape(-1, z_samples.shape[-1])\n",
    "\n",
    "    cluster_pred = np.zeros(z_samples.shape[-1], dtype=int)\n",
    "    for i in range(z_samples.shape[-1]):\n",
    "        values, counts = np.unique(z_flat[:, i], return_counts=True)\n",
    "        cluster_pred[i] = values[np.argmax(counts)]\n",
    "\n",
    "    # Assignment probabilities\n",
    "    z_probs = np.stack(\n",
    "        [\n",
    "            (z_posterior == k).mean(dim=[\"chain\", \"draw\"]).values\n",
    "            for k in range(len(sector_selectors))\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Uncertainty (entropy)\n",
    "    uncertainty = -np.sum(z_probs * np.log(z_probs + 1e-10), axis=1)\n",
    "\n",
    "    # Get posterior means and std devs from model\n",
    "    mu_posterior = idata.posterior[\"μ\"].mean(dim=[\"chain\", \"draw\"])\n",
    "    sigma_posterior = idata.posterior[\"σ\"].mean(dim=[\"chain\", \"draw\"])\n",
    "\n",
    "    # Create discriminative colors\n",
    "    unique_labels = np.unique(cluster_pred)\n",
    "    n_clusters = len(unique_labels)\n",
    "\n",
    "    # Use distinct, colorblind-friendly colors\n",
    "    colors = [\n",
    "        \"#E31A1C\",\n",
    "        \"#1F78B4\",\n",
    "        \"#33A02C\",\n",
    "        \"#FF7F00\",\n",
    "        \"#6A3D9A\",\n",
    "        \"#B15928\",\n",
    "        \"#A6CEE3\",\n",
    "        \"#B2DF8A\",\n",
    "        \"#FB9A99\",\n",
    "        \"#FDBF6F\",\n",
    "    ][:n_clusters]\n",
    "    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Create simplified 2x2 plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Plot 1: Cluster assignments with image overlay\n",
    "    ax1 = axes[0, 0]\n",
    "    if img is not None:\n",
    "        ax1.imshow(img, alpha=0.3, cmap=\"gray\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = cluster_pred == label\n",
    "        if np.any(mask):\n",
    "            ax1.scatter(\n",
    "                df_features.loc[mask, \"x\"],\n",
    "                df_features.loc[mask, \"y\"],\n",
    "                c=color_map[label],\n",
    "                s=4,\n",
    "                alpha=0.8,\n",
    "                label=f\"Cluster {label}\",\n",
    "                edgecolors=\"none\",\n",
    "            )\n",
    "\n",
    "    ax1.set_title(\"Cluster Assignments (Spatial)\", fontsize=14, fontweight=\"bold\")\n",
    "    ax1.legend(loc=\"upper right\", framealpha=0.9)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.grid(False)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "\n",
    "    # Plot 2: Assignment uncertainty\n",
    "    ax2 = axes[0, 1]\n",
    "    if img is not None:\n",
    "        ax2.imshow(img, alpha=0.3, cmap=\"gray\")\n",
    "\n",
    "    scatter = ax2.scatter(\n",
    "        df_features[\"x\"],\n",
    "        df_features[\"y\"],\n",
    "        c=uncertainty,\n",
    "        cmap=\"plasma\",\n",
    "        s=4,\n",
    "        alpha=0.8,\n",
    "        vmin=0,\n",
    "        vmax=uncertainty.max(),\n",
    "    )\n",
    "    ax2.set_title(\"Assignment Uncertainty\", fontsize=14, fontweight=\"bold\")\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.grid(False)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    cbar = plt.colorbar(scatter, ax=ax2, shrink=0.8)\n",
    "    cbar.set_label(\"Entropy\", rotation=270, labelpad=20)\n",
    "\n",
    "    # Plot 3: Feature space (if multidimensional)\n",
    "    ax3 = axes[1, 0]\n",
    "    if len(variables_names) > 1:\n",
    "        if \"V\" in df_features.columns and \"angle_rad\" in df_features.columns:\n",
    "            for label in unique_labels:\n",
    "                mask = cluster_pred == label\n",
    "                if np.any(mask):\n",
    "                    ax3.scatter(\n",
    "                        df_features.loc[mask, \"V\"],\n",
    "                        df_features.loc[mask, \"angle_rad\"],\n",
    "                        c=color_map[label],\n",
    "                        s=20,\n",
    "                        alpha=0.7,\n",
    "                        label=f\"Cluster {label}\",\n",
    "                        edgecolors=\"black\",\n",
    "                        linewidth=0.3,\n",
    "                    )\n",
    "            ax3.set_xlabel(\"Velocity Magnitude\", fontweight=\"bold\")\n",
    "            ax3.set_ylabel(\"Flow Direction (rad)\", fontweight=\"bold\")\n",
    "            ax3.set_title(\"Clusters in Feature Space\", fontsize=14, fontweight=\"bold\")\n",
    "        else:\n",
    "            feat1, feat2 = variables_names[0], variables_names[1]\n",
    "            for label in unique_labels:\n",
    "                mask = cluster_pred == label\n",
    "                if np.any(mask):\n",
    "                    ax3.scatter(\n",
    "                        df_features.loc[mask, feat1],\n",
    "                        df_features.loc[mask, feat2],\n",
    "                        c=color_map[label],\n",
    "                        s=20,\n",
    "                        alpha=0.7,\n",
    "                        label=f\"Cluster {label}\",\n",
    "                        edgecolors=\"black\",\n",
    "                        linewidth=0.3,\n",
    "                    )\n",
    "            ax3.set_xlabel(feat1, fontweight=\"bold\")\n",
    "            ax3.set_ylabel(feat2, fontweight=\"bold\")\n",
    "            ax3.set_title(\n",
    "                f\"Clusters: {feat1} vs {feat2}\", fontsize=14, fontweight=\"bold\"\n",
    "            )\n",
    "\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.legend()\n",
    "    else:\n",
    "        # For 1D case, show velocity distribution\n",
    "        feat = variables_names[0]\n",
    "        for label in unique_labels:\n",
    "            mask = cluster_pred == label\n",
    "            if np.any(mask):\n",
    "                ax3.hist(\n",
    "                    df_features.loc[mask, feat],\n",
    "                    bins=30,\n",
    "                    alpha=0.7,\n",
    "                    color=color_map[label],\n",
    "                    label=f\"Cluster {label}\",\n",
    "                    density=True,\n",
    "                )\n",
    "        ax3.set_xlabel(feat, fontweight=\"bold\")\n",
    "        ax3.set_ylabel(\"Density\", fontweight=\"bold\")\n",
    "        ax3.set_title(f\"{feat} Distribution by Cluster\", fontsize=14, fontweight=\"bold\")\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.legend()\n",
    "\n",
    "    # Plot 4: Comprehensive cluster statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis(\"off\")\n",
    "\n",
    "    # Calculate detailed statistics\n",
    "    stats_text = \"CLUSTER STATISTICS\\n\" + \"=\" * 50 + \"\\n\\n\"\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = cluster_pred == label\n",
    "        count = mask.sum()\n",
    "\n",
    "        if count == 0:\n",
    "            continue\n",
    "\n",
    "        # Spatial statistics\n",
    "        x_mean = df_features.loc[mask, \"x\"].mean()\n",
    "        y_mean = df_features.loc[mask, \"y\"].mean()\n",
    "        x_std = df_features.loc[mask, \"x\"].std()\n",
    "        y_std = df_features.loc[mask, \"y\"].std()\n",
    "\n",
    "        # Feature statistics (original scale if scaler provided)\n",
    "        feature_stats = {}\n",
    "        for i, feat_name in enumerate(variables_names):\n",
    "            if scaler is not None:\n",
    "                # Transform back to original scale for interpretation\n",
    "                feat_scaled = X_scaled[mask, i]\n",
    "                feat_original = scaler.inverse_transform(\n",
    "                    np.column_stack([X_scaled[mask, :]])\n",
    "                )[:, i]\n",
    "                feat_mean_orig = feat_original.mean()\n",
    "                feat_std_orig = feat_original.std()\n",
    "                feature_stats[feat_name] = (feat_mean_orig, feat_std_orig)\n",
    "            else:\n",
    "                feat_mean = df_features.loc[mask, feat_name].mean()\n",
    "                feat_std = df_features.loc[mask, feat_name].std()\n",
    "                feature_stats[feat_name] = (feat_mean, feat_std)\n",
    "\n",
    "        # Model parameters (posterior means)\n",
    "        model_mu = mu_posterior.values[label, :]\n",
    "        model_sigma = sigma_posterior.values[label, :]\n",
    "\n",
    "        # Uncertainty statistics\n",
    "        avg_uncertainty = uncertainty[mask].mean()\n",
    "        max_prob = z_probs[mask, label].mean()\n",
    "\n",
    "        stats_text += f\"CLUSTER {label} ({count} points)\\n\"\n",
    "        stats_text += f\"├─ Spatial Center: ({x_mean:.1f}, {y_mean:.1f})\\n\"\n",
    "        stats_text += f\"├─ Spatial Spread: (σx={x_std:.1f}, σy={y_std:.1f})\\n\"\n",
    "\n",
    "        for feat_name, (mean_val, std_val) in feature_stats.items():\n",
    "            if feat_name == \"V\":  # Velocity\n",
    "                stats_text += f\"├─ Velocity: {mean_val:.3f} ± {std_val:.3f}\\n\"\n",
    "            elif feat_name == \"angle_rad\":  # Angle\n",
    "                stats_text += f\"├─ Direction: {mean_val:.2f} ± {std_val:.2f} rad\\n\"\n",
    "            else:\n",
    "                stats_text += f\"├─ {feat_name}: {mean_val:.3f} ± {std_val:.3f}\\n\"\n",
    "\n",
    "        stats_text += f\"├─ Model μ: [{', '.join([f'{x:.2f}' for x in model_mu])}]\\n\"\n",
    "        stats_text += f\"├─ Model σ: [{', '.join([f'{x:.2f}' for x in model_sigma])}]\\n\"\n",
    "        stats_text += f\"├─ Avg Uncertainty: {avg_uncertainty:.3f}\\n\"\n",
    "        stats_text += f\"└─ Avg Probability: {max_prob:.3f}\\n\\n\"\n",
    "\n",
    "    ax4.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        stats_text,\n",
    "        transform=ax4.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "        fontfamily=\"monospace\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return cluster_pred, z_probs, uncertainty, fig\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# For multidimensional clustering\n",
    "cluster_pred, z_probs, uncertainty, fig = plot_nd_velocity_clustering(\n",
    "    df_features, X_scaled, idata_with_priors, prior_probs, img, variables_names, scaler\n",
    ")\n",
    "\n",
    "# Save the main results\n",
    "fig.savefig(\n",
    "    output_dir / f\"{base_name}_improved_results.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppcx-domains (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
