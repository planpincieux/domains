{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b2c551",
   "metadata": {},
   "source": [
    "## CLASSIGY NEW DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e564560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz as az\n",
    "import cloudpickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from ppcluster import logger\n",
    "from ppcluster.config import ConfigManager\n",
    "from ppcluster.database import (\n",
    "    get_dic_analysis_by_ids,\n",
    "    get_dic_analysis_ids,\n",
    "    get_dic_data,\n",
    "    get_image,\n",
    ")\n",
    "from ppcluster.mcmc import (\n",
    "    assign_spatial_priors,\n",
    "    compute_posterior_assignments,\n",
    "    plot_1d_velocity_clustering,\n",
    "    compute_cluster_statistics,\n",
    ")\n",
    "from ppcluster.preprocessing import (\n",
    "    apply_dic_filters,\n",
    "    preproc_features,\n",
    ")\n",
    "from ppcluster.roi import PolygonROISelector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load configuration\n",
    "config = ConfigManager()\n",
    "db_engine = create_engine(config.db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323768ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2024-08-28\"\n",
    "camera_name = \"PPCX_Tele\"\n",
    "output_dir = Path(\"output\") / f\"{camera_name}_PyMC\"\n",
    "\n",
    "# Load posterior and scaler\n",
    "PRIOR_STRENGTH = 0.4\n",
    "reference_start_date = \"2024-08-23\"\n",
    "reference_end_date = \"2024-08-28\"\n",
    "posterior_base_name = (\n",
    "    f\"PPCX_mcmc_{camera_name}_pooled_{reference_start_date}_{reference_end_date}\"\n",
    ")\n",
    "idata = az.from_netcdf(output_dir / f\"{posterior_base_name}_posterior.idata.nc\")\n",
    "scaler = joblib.load(output_dir / f\"{posterior_base_name}_scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e27085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:11:09 | [INFO    ] Found 1 DIC analyses matching criteria\n",
      "2025-09-12 16:11:10 | [INFO    ] Starting DIC filtering pipeline with 5251 points\n",
      "2025-09-12 16:11:10 | [INFO    ] Percentile filtering: 5251 -> 5145 points (removed 106 outliers)\n",
      "2025-09-12 16:11:10 | [INFO    ] Min velocity filtering: 5145 -> 5145 points (removed 0 points below 0.0)\n",
      "2025-09-12 16:11:10 | [INFO    ] DIC filtering pipeline completed: 5251 -> 5145 points (removed 106 total)\n",
      "2025-09-12 16:11:10 | [INFO    ] Data shape after filtering: (2295, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 5145 points to 2295 points inside polygon\n"
     ]
    }
   ],
   "source": [
    "# Get DIC data\n",
    "dic_ids = get_dic_analysis_ids(db_engine, camera_name=camera_name, reference_date=date)\n",
    "if len(dic_ids) == 0:\n",
    "    raise ValueError(\"No DIC analyses found for the given criteria\")\n",
    "elif len(dic_ids) > 1:\n",
    "    logger.warning(\n",
    "        \"Multiple DIC analyses found for the given criteria. Using the first one.\"\n",
    "    )\n",
    "dic_id = dic_ids[0]\n",
    "\n",
    "dic_analyses = get_dic_analysis_by_ids(db_engine=db_engine, dic_ids=[dic_id])\n",
    "master_image_id = dic_analyses[\"master_image_id\"].iloc[0]\n",
    "img = get_image(\n",
    "    master_image_id,\n",
    "    camera_name=camera_name,\n",
    "    config=config,\n",
    ")\n",
    "df = get_dic_data(dic_id, config=config)\n",
    "df = apply_dic_filters(\n",
    "    df,\n",
    "    filter_outliers=config.get(\"dic.filter_outliers\"),\n",
    "    tails_percentile=config.get(\"dic.tails_percentile\"),\n",
    ")\n",
    "\n",
    "selector = PolygonROISelector.from_file(config.get(\"data.roi_path\"))\n",
    "df = selector.filter_dataframe(df, x_col=\"x\", y_col=\"y\")\n",
    "logger.info(f\"Data shape after filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9c347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:11:10 | [INFO    ] Sector 0: 297 points with strong prior\n",
      "2025-09-12 16:11:10 | [INFO    ] Sector 1: 407 points with strong prior\n",
      "2025-09-12 16:11:10 | [INFO    ] Sector 2: 440 points with strong prior\n",
      "2025-09-12 16:11:10 | [INFO    ] Sector 3: 963 points with strong prior\n"
     ]
    }
   ],
   "source": [
    "# Prepare new data\n",
    "variables_names = config.get(\"clustering.variables_names\")\n",
    "df_features = preproc_features(df)\n",
    "X = df_features[variables_names].values\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# # Assign spatial priors\n",
    "sector_files = sorted(glob.glob(config.get(\"data.sector_prior_pattern\")))\n",
    "sector_selectors = [PolygonROISelector.from_file(f) for f in sector_files]\n",
    "prior_probs = assign_spatial_priors(df, sector_selectors, prior_strength=PRIOR_STRENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:11:11 | [INFO    ] Results saved to output/PPCX_Tele_PyMC/PPCX_mcmc_PPCX_Tele_2024-08-28_dic-634_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# compute assignments for new single-day data (fast option using posterior mean)\n",
    "posterior_probs, cluster_pred, entropy = compute_posterior_assignments(\n",
    "    idata, X_scaled, prior_probs, use_posterior_mean=True\n",
    ")\n",
    "\n",
    "# Save results to pickle\n",
    "outbasepath = output_dir / f\"PPCX_mcmc_{camera_name}_{date}_dic-{dic_id}_results\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "with open(outbasepath.with_suffix(\".pkl\"), \"wb\") as f:\n",
    "    cloudpickle.dump(\n",
    "        {\n",
    "            \"data\": df,\n",
    "            \"df_features\": df_features,\n",
    "            \"var_names\": variables_names,\n",
    "            \"features_scaled\": X_scaled,\n",
    "            \"posterior_probs\": posterior_probs,\n",
    "            \"cluster_pred\": cluster_pred,\n",
    "            \"entropy\": entropy,\n",
    "            \"scaler\": scaler,\n",
    "            \"idata\": idata,\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "    logger.info(f\"Results saved to {outbasepath.with_suffix('.pkl')}\")\n",
    "\n",
    "# Plot results\n",
    "fig, uncertainty, stats = plot_1d_velocity_clustering(\n",
    "    df_features,\n",
    "    img,\n",
    "    idata=idata,\n",
    "    cluster_pred=cluster_pred,\n",
    "    posterior_probs=posterior_probs,\n",
    "    scaler=scaler,\n",
    ")\n",
    "fig.savefig(\n",
    "    outbasepath.with_suffix(\".png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing\n",
    "median_entropy_treshold = 0.6\n",
    "median_entropy = np.median(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fed64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(stats).T\n",
    "stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def create_2d_grid(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    labels: np.ndarray | None = None,\n",
    "    grid_spacing: float | None = None,\n",
    "):\n",
    "    if grid_spacing is None:\n",
    "        # Estimate grid spacing from minimum distances\n",
    "        points = np.column_stack((x, y))\n",
    "        tree = cKDTree(points)\n",
    "        # Query the nearest neighbor point (k=2)\n",
    "        distances, _ = tree.query(points, k=2)\n",
    "        # distances[:, 1] is distance to nearest neighbor\n",
    "        grid_spacing = np.median(distances[:, 1])\n",
    "        if any(np.isnan(distances[:, 1])):\n",
    "            logger.warning(\"Some points have no neighbors within the search radius.\")\n",
    "        if any(distances[:, 1] != grid_spacing):\n",
    "            logger.warning(\n",
    "                \"Points are not on a regular grid. Interpolation may be needed.\"\n",
    "            )\n",
    "        logger.info(f\"Estimated grid spacing: {grid_spacing:.2f}\")\n",
    "\n",
    "    # Create regular grid\n",
    "    x_min, x_max = df[\"x\"].min(), df[\"x\"].max()\n",
    "    y_min, y_max = df[\"y\"].min(), df[\"y\"].max()\n",
    "    x_grid = np.arange(x_min, x_max + grid_spacing, grid_spacing)\n",
    "    y_grid = np.arange(y_min, y_max + grid_spacing, grid_spacing)\n",
    "\n",
    "    # Create meshgrid\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    # Initialize with NaN for no label\n",
    "    label_grid = np.full(X.shape, np.nan)\n",
    "\n",
    "    if labels is not None:\n",
    "        # Map the labels to the grid\n",
    "        for i, (xi, yi) in enumerate(zip(x, y)):\n",
    "            ix = np.argmin(np.abs(x_grid - xi))\n",
    "            iy = np.argmin(np.abs(y_grid - yi))\n",
    "            label_grid[iy, ix] = labels[i]\n",
    "\n",
    "    return X, Y, label_grid\n",
    "\n",
    "\n",
    "def remove_small_grid_components(label_grid, min_size=5, connectivity=8):\n",
    "    \"\"\"\n",
    "    Remove/merge small connected components in a 2D label grid.\n",
    "    Small components are reassigned to the most common neighbor label (if any),\n",
    "    otherwise set to NaN.\n",
    "    Args:\n",
    "        label_grid: 2D numpy array with labels (can contain np.nan for empty cells)\n",
    "        min_size: minimum size (in grid cells) to keep a component\n",
    "        connectivity: 4 or 8 (neighbors)\n",
    "    Returns:\n",
    "        cleaned_grid: 2D array with small components merged/removed\n",
    "    \"\"\"\n",
    "    cleaned = label_grid.copy().astype(float)\n",
    "    structure = (\n",
    "        np.ones((3, 3), dtype=bool)\n",
    "        if connectivity == 8\n",
    "        else np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=bool)\n",
    "    )\n",
    "\n",
    "    # iterate over each distinct label value (ignore NaN)\n",
    "    unique_labels = np.unique(label_grid[~np.isnan(label_grid)])\n",
    "    for lab in unique_labels:\n",
    "        mask = label_grid == lab\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        components, ncomp = ndimage.label(mask, structure=structure)\n",
    "        for comp_id in range(1, ncomp + 1):\n",
    "            comp_mask = components == comp_id\n",
    "            comp_size = comp_mask.sum()\n",
    "            if comp_size < min_size:\n",
    "                # dilate component to get neighbor cells\n",
    "                nb_mask = ndimage.binary_dilation(\n",
    "                    comp_mask, structure=np.ones((3, 3))\n",
    "                ) & (~comp_mask)\n",
    "                neighbor_labels = cleaned[nb_mask]\n",
    "                # exclude NaNs and the same label\n",
    "                neighbor_labels = neighbor_labels[~np.isnan(neighbor_labels)]\n",
    "                neighbor_labels = neighbor_labels[neighbor_labels != lab]\n",
    "                if neighbor_labels.size > 0:\n",
    "                    # pick most common neighbor label\n",
    "                    new_label = np.bincount(neighbor_labels.astype(int)).argmax()\n",
    "                    cleaned[comp_mask] = new_label\n",
    "                else:\n",
    "                    cleaned[comp_mask] = np.nan\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def plot_cluster_labels_on_image(\n",
    "    df_features,\n",
    "    img,\n",
    "    cluster_pred,\n",
    "    ax=None,\n",
    "    title=\"Velocity-Based Spatial Clustering\",\n",
    "    markersize=8,\n",
    "):\n",
    "    \"\"\"Plot cluster labels over optional background image.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title(title, fontsize=14, pad=10)\n",
    "    if img is not None:\n",
    "        ax.imshow(img, alpha=0.3, cmap=\"gray\")\n",
    "\n",
    "    unique_labels = np.unique(cluster_pred)\n",
    "    palette = [\n",
    "        \"#E31A1C\",\n",
    "        \"#1F78B4\",\n",
    "        \"#33A02C\",\n",
    "        \"#FF7F00\",\n",
    "        \"#6A3D9A\",\n",
    "        \"#B15928\",\n",
    "        \"#A6CEE3\",\n",
    "        \"#B2DF8A\",\n",
    "        \"#FB9A99\",\n",
    "        \"#FDBF6F\",\n",
    "    ]\n",
    "    color_map = {}\n",
    "    for i, lab in enumerate(sorted(unique_labels)):\n",
    "        color_map[lab] = \"#7f7f7f\" if lab == -1 else palette[i % len(palette)]\n",
    "\n",
    "    for label in sorted(unique_labels):\n",
    "        mask = cluster_pred == label\n",
    "        if np.any(mask):\n",
    "            ax.scatter(\n",
    "                df_features.loc[mask, \"x\"],\n",
    "                df_features.loc[mask, \"y\"],\n",
    "                c=color_map[label],\n",
    "                s=markersize,\n",
    "                alpha=0.8,\n",
    "                label=f\"Cluster {label}\",\n",
    "                edgecolors=\"none\",\n",
    "            )\n",
    "\n",
    "    ax.legend(loc=\"upper right\", framealpha=0.9, fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def close_small_holes(\n",
    "    label_grid, max_hole_size=10, connectivity=8, require_single_neighbor=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Close small NaN-holes in a 2D label grid.\n",
    "\n",
    "    Rules:\n",
    "      - Only close holes whose size (number of NaN cells) <= max_hole_size.\n",
    "      - Only close if the dilated border of the hole contains no NaNs\n",
    "        (i.e. data all around the hole).\n",
    "      - If require_single_neighbor is True the border must contain a single unique\n",
    "        label; otherwise the most common border label is used.\n",
    "\n",
    "    Args:\n",
    "      label_grid: 2D ndarray with labels (NaN for empty cells).\n",
    "      max_hole_size: maximum hole area (in grid cells) to fill.\n",
    "      connectivity: 4 or 8 connectivity for labeling/dilation.\n",
    "      require_single_neighbor: if True, require single neighbor label on border.\n",
    "\n",
    "    Returns:\n",
    "      new_grid: copy of label_grid with selected holes filled.\n",
    "    \"\"\"\n",
    "    new_grid = label_grid.copy().astype(float)\n",
    "    structure = (\n",
    "        np.ones((3, 3), dtype=bool)\n",
    "        if connectivity == 8\n",
    "        else np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=bool)\n",
    "    )\n",
    "\n",
    "    # mask of holes (NaNs)\n",
    "    hole_mask_all = np.isnan(label_grid)\n",
    "    if not np.any(hole_mask_all):\n",
    "        return new_grid\n",
    "\n",
    "    # label each hole component\n",
    "    comp_labels, ncomp = ndimage.label(hole_mask_all, structure=structure)\n",
    "    for comp_id in range(1, ncomp + 1):\n",
    "        comp_mask = comp_labels == comp_id\n",
    "        comp_size = int(comp_mask.sum())\n",
    "        if comp_size > max_hole_size:\n",
    "            continue\n",
    "\n",
    "        # dilate to get border cells\n",
    "        dilated = ndimage.binary_dilation(comp_mask, structure=np.ones((3, 3)))\n",
    "        border_mask = dilated & (~comp_mask)\n",
    "\n",
    "        # if any border cell is NaN -> not fully surrounded by data\n",
    "        border_vals = new_grid[border_mask]\n",
    "        if border_vals.size == 0 or np.any(np.isnan(border_vals)):\n",
    "            continue\n",
    "\n",
    "        # get unique neighbor labels\n",
    "        unique_neighbors, counts = np.unique(border_vals, return_counts=True)\n",
    "        if unique_neighbors.size == 0:\n",
    "            continue\n",
    "\n",
    "        if require_single_neighbor:\n",
    "            # require border to be all same label\n",
    "            if unique_neighbors.size == 1:\n",
    "                fill_label = unique_neighbors[0]\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            # pick most common neighbor label\n",
    "            fill_label = unique_neighbors[np.argmax(counts)]\n",
    "\n",
    "        # fill hole with chosen label\n",
    "        new_grid[comp_mask] = fill_label\n",
    "\n",
    "    return new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, label_grid = create_2d_grid(\n",
    "    x=df[\"x\"].values, y=df[\"y\"].values, labels=cluster_pred, grid_spacing=None\n",
    ")\n",
    "\n",
    "# Usage (after you built X, Y, label_grid)\n",
    "min_size = 20\n",
    "cleaned_grid = remove_small_grid_components(\n",
    "    label_grid, min_size=min_size, connectivity=8\n",
    ")\n",
    "min_size = 5\n",
    "cleaned_grid = remove_small_grid_components(\n",
    "    cleaned_grid, min_size=min_size, connectivity=8\n",
    ")\n",
    "cleaned_grid_filled = close_small_holes(\n",
    "    cleaned_grid, max_hole_size=30, connectivity=8, require_single_neighbor=True\n",
    ")\n",
    "\n",
    "# Map cleaned grid back to original point ordering\n",
    "# x coordinates per column: X[0, :]\n",
    "# y coordinates per row:    Y[:, 0]\n",
    "x_grid = X[0, :]\n",
    "y_grid = Y[:, 0]\n",
    "point_labels_cleaned = np.full(df.shape[0], np.nan)\n",
    "for i, (xi, yi) in enumerate(zip(df[\"x\"].values, df[\"y\"].values)):\n",
    "    ix = np.argmin(np.abs(x_grid - xi))\n",
    "    iy = np.argmin(np.abs(y_grid - yi))\n",
    "    val = cleaned_grid_filled[iy, ix]\n",
    "    point_labels_cleaned[i] = -1 if np.isnan(val) else int(val)\n",
    "\n",
    "# replace cluster_pred or keep both\n",
    "cluster_pred_cleaned = point_labels_cleaned.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plot_cluster_labels_on_image(df_features, img, cluster_pred, ax=axes[0])\n",
    "plot_cluster_labels_on_image(df_features, img, cluster_pred_cleaned, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = compute_cluster_statistics(\n",
    "    df_features,\n",
    "    cluster_pred=cluster_pred_cleaned,\n",
    "    posterior_probs=posterior_probs,\n",
    "    idata=idata,\n",
    "    scaler=scaler,\n",
    ")\n",
    "cluster_stats = pd.DataFrame(cluster_stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fdd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppcx-domains (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
